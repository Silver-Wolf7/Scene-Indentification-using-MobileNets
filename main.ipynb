{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.applications import MobileNet\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_labels(file):\n",
    "    labels_file = open(file, \"r\")\n",
    "    labels = []\n",
    "    \n",
    "    for line in labels_file:\n",
    "        label = line.strip()\n",
    "        labels.append(label)\n",
    "    \n",
    "    labels_file.close()\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "#list of all labels\n",
    "class_names = list_labels(\"./CamSDD/Labels.txt\")\n",
    "class_name_labels = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "\n",
    "\n",
    "def load_data(folder):\n",
    "    Category = [\"training\", \"test\", \"validation\"]\n",
    "    output = []\n",
    "    \n",
    "    for category in Category:\n",
    "        print(\"Loading {}\".format(category))\n",
    "        path = os.path.join(folder, category)\n",
    "        print(path)\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for sub_folder in os.listdir(path):\n",
    "            label = class_name_labels[sub_folder]\n",
    "            \n",
    "            #Iterating through all images\n",
    "            for file in os.listdir(os.path.join(path, sub_folder)):\n",
    "                \n",
    "                #getting the image path\n",
    "                img_path = os.path.join(os.path.join(path, sub_folder), file)\n",
    "                \n",
    "                #appending image and corresponding label\n",
    "                images.append(cv2.imread(img_path))\n",
    "                labels.append(label)\n",
    "            \n",
    "        #check that data type doesn't affect accuracy\n",
    "        images = np.array(images, dtype='float32')\n",
    "        labels = np.array(labels, dtype='int32')\n",
    "        \n",
    "        output.append((images, labels))\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "#displays 25 images with labels\n",
    "def display_examples(class_names, images, labels):\n",
    "    figsize = (20, 20)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    fig.suptitle(\"Example of images\", fontsize=16)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        # image = cv2.resize(images[i], figsize)\n",
    "        plt.imshow(images[i].astype(np.uint8))\n",
    "        plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training\n",
      ".\\CamSDD\\training\n",
      "Loading test\n",
      ".\\CamSDD\\test\n",
      "Loading validation\n",
      ".\\CamSDD\\validation\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels), (validation_images, validation_labels)= load_data(\".\\\\CamSDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 24.5 GiB for an array with shape (9898, 384, 576, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#shuffling train data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_images, train_labels \u001b[39m=\u001b[39m shuffle(train_images, train_labels, random_state\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Iman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:651\u001b[0m, in \u001b[0;36mshuffle\u001b[1;34m(random_state, n_samples, *arrays)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshuffle\u001b[39m(\u001b[39m*\u001b[39marrays, random_state\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, n_samples\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\"\"Shuffle arrays or sparse matrices in a consistent way.\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \n\u001b[0;32m    588\u001b[0m \u001b[39m    This is a convenience alias to ``resample(*arrays, replace=False)`` to do\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[39m    resample\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 651\u001b[0m     \u001b[39mreturn\u001b[39;00m resample(\n\u001b[0;32m    652\u001b[0m         \u001b[39m*\u001b[39;49marrays, replace\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, n_samples\u001b[39m=\u001b[39;49mn_samples, random_state\u001b[39m=\u001b[39;49mrandom_state\n\u001b[0;32m    653\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Iman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:577\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(replace, n_samples, random_state, stratify, *arrays)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[39m# convert sparse matrices to CSR for row-based indexing\u001b[39;00m\n\u001b[0;32m    576\u001b[0m arrays \u001b[39m=\u001b[39m [a\u001b[39m.\u001b[39mtocsr() \u001b[39mif\u001b[39;00m issparse(a) \u001b[39melse\u001b[39;00m a \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 577\u001b[0m resampled_arrays \u001b[39m=\u001b[39m [_safe_indexing(a, indices) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m    578\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(resampled_arrays) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    579\u001b[0m     \u001b[39m# syntactic sugar for the unit argument case\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m resampled_arrays[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Iman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:577\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[39m# convert sparse matrices to CSR for row-based indexing\u001b[39;00m\n\u001b[0;32m    576\u001b[0m arrays \u001b[39m=\u001b[39m [a\u001b[39m.\u001b[39mtocsr() \u001b[39mif\u001b[39;00m issparse(a) \u001b[39melse\u001b[39;00m a \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 577\u001b[0m resampled_arrays \u001b[39m=\u001b[39m [_safe_indexing(a, indices) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m    578\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(resampled_arrays) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    579\u001b[0m     \u001b[39m# syntactic sugar for the unit argument case\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m resampled_arrays[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Iman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:361\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[39mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m    360\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 361\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_indexing(X, indices, indices_dtype, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m    362\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    363\u001b[0m     \u001b[39mreturn\u001b[39;00m _list_indexing(X, indices, indices_dtype)\n",
      "File \u001b[1;32mc:\\Users\\Iman\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:185\u001b[0m, in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    184\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m--> 185\u001b[0m \u001b[39mreturn\u001b[39;00m array[key] \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m array[:, key]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 24.5 GiB for an array with shape (9898, 384, 576, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "#shuffling train data\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_examples(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "#imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "#check how many neurons should be discarded\n",
    "base_model=MobileNet(weights='imagenet',include_top=False) \n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024, activation='sigmoid')(x)\n",
    "x=Dropout(0.7)(x)\n",
    "output = Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_2\n",
      "1 conv1\n",
      "2 conv1_bn\n",
      "3 conv1_relu\n",
      "4 conv_dw_1\n",
      "5 conv_dw_1_bn\n",
      "6 conv_dw_1_relu\n",
      "7 conv_pw_1\n",
      "8 conv_pw_1_bn\n",
      "9 conv_pw_1_relu\n",
      "10 conv_pad_2\n",
      "11 conv_dw_2\n",
      "12 conv_dw_2_bn\n",
      "13 conv_dw_2_relu\n",
      "14 conv_pw_2\n",
      "15 conv_pw_2_bn\n",
      "16 conv_pw_2_relu\n",
      "17 conv_dw_3\n",
      "18 conv_dw_3_bn\n",
      "19 conv_dw_3_relu\n",
      "20 conv_pw_3\n",
      "21 conv_pw_3_bn\n",
      "22 conv_pw_3_relu\n",
      "23 conv_pad_4\n",
      "24 conv_dw_4\n",
      "25 conv_dw_4_bn\n",
      "26 conv_dw_4_relu\n",
      "27 conv_pw_4\n",
      "28 conv_pw_4_bn\n",
      "29 conv_pw_4_relu\n",
      "30 conv_dw_5\n",
      "31 conv_dw_5_bn\n",
      "32 conv_dw_5_relu\n",
      "33 conv_pw_5\n",
      "34 conv_pw_5_bn\n",
      "35 conv_pw_5_relu\n",
      "36 conv_pad_6\n",
      "37 conv_dw_6\n",
      "38 conv_dw_6_bn\n",
      "39 conv_dw_6_relu\n",
      "40 conv_pw_6\n",
      "41 conv_pw_6_bn\n",
      "42 conv_pw_6_relu\n",
      "43 conv_dw_7\n",
      "44 conv_dw_7_bn\n",
      "45 conv_dw_7_relu\n",
      "46 conv_pw_7\n",
      "47 conv_pw_7_bn\n",
      "48 conv_pw_7_relu\n",
      "49 conv_dw_8\n",
      "50 conv_dw_8_bn\n",
      "51 conv_dw_8_relu\n",
      "52 conv_pw_8\n",
      "53 conv_pw_8_bn\n",
      "54 conv_pw_8_relu\n",
      "55 conv_dw_9\n",
      "56 conv_dw_9_bn\n",
      "57 conv_dw_9_relu\n",
      "58 conv_pw_9\n",
      "59 conv_pw_9_bn\n",
      "60 conv_pw_9_relu\n",
      "61 conv_dw_10\n",
      "62 conv_dw_10_bn\n",
      "63 conv_dw_10_relu\n",
      "64 conv_pw_10\n",
      "65 conv_pw_10_bn\n",
      "66 conv_pw_10_relu\n",
      "67 conv_dw_11\n",
      "68 conv_dw_11_bn\n",
      "69 conv_dw_11_relu\n",
      "70 conv_pw_11\n",
      "71 conv_pw_11_bn\n",
      "72 conv_pw_11_relu\n",
      "73 conv_pad_12\n",
      "74 conv_dw_12\n",
      "75 conv_dw_12_bn\n",
      "76 conv_dw_12_relu\n",
      "77 conv_pw_12\n",
      "78 conv_pw_12_bn\n",
      "79 conv_pw_12_relu\n",
      "80 conv_dw_13\n",
      "81 conv_dw_13_bn\n",
      "82 conv_dw_13_relu\n",
      "83 conv_pw_13\n",
      "84 conv_pw_13_bn\n",
      "85 conv_pw_13_relu\n",
      "86 global_average_pooling2d_1\n",
      "87 dense_2\n",
      "88 dropout_1\n",
      "89 dense_3\n"
     ]
    }
   ],
   "source": [
    "#checking model architecture\n",
    "# print(model.summary())\n",
    "for i,layer in enumerate(model.layers):\n",
    "  print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the ones we created above (check which method)\n",
    "# for layer in model.layers[:-4]:\n",
    "#     layer.trainable=False\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "495/495 [==============================] - 318s 639ms/step - loss: 2.3580\n",
      "Epoch 2/15\n",
      "495/495 [==============================] - 306s 619ms/step - loss: 2.0688\n",
      "Epoch 3/15\n",
      "495/495 [==============================] - ETA: 0s - loss: 1.8990\n",
      "on epoch  3  lr was adjusted from  9.999999747378752e-05  to  9.999999747378752e-06\n",
      "495/495 [==============================] - 298s 601ms/step - loss: 1.8990\n",
      "Epoch 4/15\n",
      "495/495 [==============================] - 299s 603ms/step - loss: 1.8155\n",
      "Epoch 5/15\n",
      "495/495 [==============================] - 300s 606ms/step - loss: 1.7939\n",
      "Epoch 6/15\n",
      "495/495 [==============================] - ETA: 0s - loss: 1.7818\n",
      "on epoch  6  lr was adjusted from  9.999999747378752e-06  to  9.999999747378752e-07\n",
      "495/495 [==============================] - 298s 603ms/step - loss: 1.7818\n",
      "Epoch 7/15\n",
      "495/495 [==============================] - 298s 601ms/step - loss: 1.7620\n",
      "Epoch 8/15\n",
      "495/495 [==============================] - 298s 602ms/step - loss: 1.7678\n",
      "Epoch 9/15\n",
      "495/495 [==============================] - ETA: 0s - loss: 1.7702\n",
      "on epoch  9  lr was adjusted from  9.999999974752427e-07  to  9.999999974752428e-08\n",
      "495/495 [==============================] - 299s 604ms/step - loss: 1.7702\n",
      "Epoch 10/15\n",
      "495/495 [==============================] - 299s 604ms/step - loss: 1.7590\n",
      "Epoch 11/15\n",
      "495/495 [==============================] - 297s 599ms/step - loss: 1.7612\n",
      "Epoch 12/15\n",
      "495/495 [==============================] - ETA: 0s - loss: 1.7663\n",
      "on epoch  12  lr was adjusted from  1.0000000116860974e-07  to  1.0000000116860975e-08\n",
      "495/495 [==============================] - 298s 603ms/step - loss: 1.7663\n",
      "Epoch 13/15\n",
      "495/495 [==============================] - 298s 602ms/step - loss: 1.7689\n",
      "Epoch 14/15\n",
      "495/495 [==============================] - 299s 604ms/step - loss: 1.7606\n",
      "Epoch 15/15\n",
      "495/495 [==============================] - ETA: 0s - loss: 1.7675\n",
      "on epoch  15  lr was adjusted from  9.99999993922529e-09  to  9.999999939225292e-10\n",
      "495/495 [==============================] - 296s 598ms/step - loss: 1.7675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bbc809250>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#conclude: one of the two decay methods are incorrect\n",
    "# check what loss function they used\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-4,\n",
    "    decay_steps=1485,\n",
    "    decay_rate=0.1)\n",
    "\n",
    "class PRINTLR(keras.callbacks.Callback):\n",
    "    def __init__ (self, model):\n",
    "        self.model=model\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "        print('\\non epoch ',epoch + 1, ' lr was adjusted to ', lr)\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=lr_schedule), loss='sparse_categorical_crossentropy')\n",
    "model.fit(train_images, train_labels, batch_size=20, epochs=15, callbacks=[PRINTLR(model)])\n",
    "\n",
    "# class ADJUSTLR(keras.callbacks.Callback):\n",
    "#     def __init__ (self, model, freq, factor, verbose):\n",
    "#         self.model=model\n",
    "#         self.freq=freq\n",
    "#         self.factor =factor\n",
    "#         self.verbose=verbose\n",
    "#         self.adj_epoch=freq\n",
    "#     def on_epoch_end(self, epoch, logs=None):\n",
    "#         if epoch + 1 == self.adj_epoch: # adjust the learning rate\n",
    "#             lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "#             new_lr=lr * self.factor\n",
    "#             self.adj_epoch +=self.freq\n",
    "#             if self.verbose == 1:\n",
    "#                 print('\\non epoch ',epoch + 1, ' lr was adjusted from ', lr, ' to ', new_lr)\n",
    "#             tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "# freq=3\n",
    "# factor=0.1\n",
    "# verbose=1\n",
    "# callbacks=[ADJUSTLR(model, freq, factor, verbose)]\n",
    "# model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy')\n",
    "# model.fit(train_images, train_labels, batch_size=20, epochs=15, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 21s 933ms/step - loss: 1.6270\n"
     ]
    }
   ],
   "source": [
    "test_loss = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 18s 938ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.25      0.36        20\n",
      "           1       0.47      0.75      0.58        20\n",
      "           2       0.33      0.05      0.09        20\n",
      "           3       0.23      0.50      0.32        20\n",
      "           4       0.33      0.05      0.09        20\n",
      "           5       0.33      0.35      0.34        20\n",
      "           6       0.52      0.75      0.61        20\n",
      "           7       0.58      0.55      0.56        20\n",
      "           8       0.66      0.95      0.78        20\n",
      "           9       0.47      0.75      0.58        20\n",
      "          10       0.78      0.70      0.74        20\n",
      "          11       0.71      0.50      0.59        20\n",
      "          12       0.70      0.80      0.74        20\n",
      "          13       0.63      0.85      0.72        20\n",
      "          14       0.60      0.75      0.67        20\n",
      "          15       0.63      0.60      0.62        20\n",
      "          16       0.57      0.65      0.60        20\n",
      "          17       0.39      0.35      0.37        20\n",
      "          18       0.54      0.65      0.59        20\n",
      "          19       0.58      0.35      0.44        20\n",
      "          20       0.62      0.50      0.56        20\n",
      "          21       0.65      0.65      0.65        20\n",
      "          22       0.68      0.65      0.67        20\n",
      "          23       0.79      0.55      0.65        20\n",
      "          24       1.00      0.50      0.67        20\n",
      "          25       0.56      0.75      0.64        20\n",
      "          26       0.69      0.45      0.55        20\n",
      "          27       0.64      0.80      0.71        20\n",
      "          28       0.86      0.60      0.71        20\n",
      "          29       0.85      0.85      0.85        20\n",
      "\n",
      "    accuracy                           0.58       600\n",
      "   macro avg       0.60      0.58      0.57       600\n",
      "weighted avg       0.60      0.58      0.57       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05f77207d599572d981daf736ca0d1eaa03a714dfd02cbbd00a3d96185cb54ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
