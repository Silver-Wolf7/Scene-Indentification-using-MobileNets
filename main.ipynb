{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 12:53:51.844997: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-17 12:53:52.039404: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/cserv1_a/soc_ug/fy19iars/project/lib/python3.9/site-packages/cv2/../../lib64:/uollinapps/AppsData/src/vscode/1.71.2-1663191299.el7/lib64\n",
      "2023-02-17 12:53:52.039437: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-17 12:53:54.654987: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/cserv1_a/soc_ug/fy19iars/project/lib/python3.9/site-packages/cv2/../../lib64:/uollinapps/AppsData/src/vscode/1.71.2-1663191299.el7/lib64\n",
      "2023-02-17 12:53:54.655165: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/cserv1_a/soc_ug/fy19iars/project/lib/python3.9/site-packages/cv2/../../lib64:/uollinapps/AppsData/src/vscode/1.71.2-1663191299.el7/lib64\n",
      "2023-02-17 12:53:54.655180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from keras.applications import MobileNet\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, GlobalMaxPooling2D, Activation, Multiply, Conv2D, Concatenate, Flatten\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam \n",
    "from keras.callbacks import EarlyStopping\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(25)\n",
    "tf.random.set_seed(25)\n",
    "tf.keras.utils.set_random_seed(25)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_labels(file):\n",
    "    labels_file = open(file, \"r\")\n",
    "    labels = []\n",
    "    \n",
    "    for line in labels_file:\n",
    "        label = line.strip()\n",
    "        labels.append(label)\n",
    "    \n",
    "    labels_file.close()\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "#list of all labels\n",
    "class_names = list_labels(\"./CamSDD/Labels.txt\")\n",
    "class_name_labels = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "\n",
    "\n",
    "def load_data(folder):\n",
    "    Category = [\"training\", \"test\", \"validation\"]\n",
    "    output = []\n",
    "    \n",
    "    for category in Category:\n",
    "        print(\"Loading {}\".format(category))\n",
    "        path = os.path.join(folder, category)\n",
    "        print(path)\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for sub_folder in os.listdir(path):\n",
    "            label = class_name_labels[sub_folder]\n",
    "            \n",
    "            #Iterating through all images\n",
    "            for file in os.listdir(os.path.join(path, sub_folder)):\n",
    "                \n",
    "                #getting the image path\n",
    "                img_path = os.path.join(os.path.join(path, sub_folder), file)\n",
    "                \n",
    "                #appending image and corresponding label\n",
    "                images.append(cv2.resize(cv2.imread(img_path), (224, 224)))\n",
    "                # images.append(cv2.imread(img_path))\n",
    "                labels.append(label)\n",
    "            \n",
    "        #check that data type doesn't affect accuracy\n",
    "        images = np.array(images, dtype='float32')/255\n",
    "        labels = np.array(labels, dtype='int8')\n",
    "        \n",
    "        output.append((images, labels))\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "#displays 25 images with labels\n",
    "def display_examples(class_names, images, labels):\n",
    "    figsize = (20, 20)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    fig.suptitle(\"Example of images\", fontsize=16)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        # image = cv2.resize(images[i], figsize)\n",
    "        plt.imshow(images[i].astype(np.uint8))\n",
    "        plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training\n",
      "./CamSDD/training\n",
      "Loading test\n",
      "./CamSDD/test\n",
      "Loading validation\n",
      "./CamSDD/validation\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels), (validation_images, validation_labels)= load_data(\"./CamSDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling train data\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)\n",
    "validation_images, validation_labels = shuffle(validation_images, validation_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_examples(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel module\n",
    "def channel_attention_module(x, ratio=16):\n",
    "    b, _, _, channel = x.shape\n",
    "    # MLP shared layer\n",
    "    l1 = Dense(channel//ratio, activation=\"relu\", use_bias=True)\n",
    "    l2 = Dense(channel, use_bias=False)\n",
    "    \n",
    "    # Global Average pooling\n",
    "    x1 = GlobalAveragePooling2D()(x)\n",
    "    x1 = l1(x1)\n",
    "    x1 = l2(x1)\n",
    "    \n",
    "    # Global Max pooling\n",
    "    x2 = GlobalMaxPooling2D()(x)\n",
    "    x2 = l1(x2)\n",
    "    x2 = l2(x2)\n",
    "    \n",
    "    # Adding both and applying sigmoid\n",
    "    features = x1 + x2\n",
    "    features = Activation(\"sigmoid\")(features)\n",
    "    features = Multiply()([x, features])\n",
    "    \n",
    "    return features\n",
    "\n",
    "# spatial attention module\n",
    "def spatial_attention_module(x):\n",
    "    # Average pooling\n",
    "    x1 = tf.reduce_mean(x, axis=-1)\n",
    "    x1 = tf.expand_dims(x1, axis=-1)\n",
    "    \n",
    "    # Max pooling\n",
    "    x2 = tf.reduce_max(x, axis=-1)\n",
    "    x2 = tf.expand_dims(x2, axis=-1)\n",
    "    \n",
    "    # Concatenate\n",
    "    features = Concatenate()([x1, x2])\n",
    "    \n",
    "    # Conv layer\n",
    "    features = Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(features)\n",
    "    features = Multiply()([x, features])\n",
    "    \n",
    "    return features\n",
    "    \n",
    "# CBAM\n",
    "def CBAM(x):\n",
    "    x = channel_attention_module(x)\n",
    "    x = spatial_attention_module(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-17 12:55:10.759414: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/cserv1_a/soc_ug/fy19iars/project/lib/python3.9/site-packages/cv2/../../lib64:/uollinapps/AppsData/src/vscode/1.71.2-1663191299.el7/lib64\n",
      "2023-02-17 12:55:10.759467: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-17 12:55:10.759567: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (feng-linux-04.leeds.ac.uk): /proc/driver/nvidia/version does not exist\n",
      "2023-02-17 12:55:10.760003: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "base_model=MobileNet(weights='imagenet', include_top=False) \n",
    "\n",
    "x=base_model.output\n",
    "\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024, activation='sigmoid')(x)\n",
    "x=Dropout(0.7)(x)\n",
    "output = Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking model architecture\n",
    "# print(model.summary())\n",
    "for i,layer in enumerate(model.layers):\n",
    "  print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "495/495 [==============================] - 55s 107ms/step - loss: 2.3517 - accuracy: 0.3938 - val_loss: 1.1229 - val_accuracy: 0.8300\n",
      "Epoch 2/100\n",
      "495/495 [==============================] - 52s 106ms/step - loss: 1.0649 - accuracy: 0.7365 - val_loss: 0.6769 - val_accuracy: 0.8650\n",
      "Epoch 3/100\n",
      "495/495 [==============================] - 52s 105ms/step - loss: 0.7460 - accuracy: 0.8040 - val_loss: 0.5281 - val_accuracy: 0.8783\n",
      "Epoch 4/100\n",
      "495/495 [==============================] - 51s 102ms/step - loss: 0.5941 - accuracy: 0.8360 - val_loss: 0.4490 - val_accuracy: 0.8883\n",
      "Epoch 5/100\n",
      "495/495 [==============================] - 52s 104ms/step - loss: 0.5123 - accuracy: 0.8588 - val_loss: 0.4039 - val_accuracy: 0.8883\n",
      "Epoch 6/100\n",
      "495/495 [==============================] - 51s 104ms/step - loss: 0.4501 - accuracy: 0.8722 - val_loss: 0.3705 - val_accuracy: 0.9000\n",
      "Epoch 7/100\n",
      "495/495 [==============================] - 52s 104ms/step - loss: 0.4097 - accuracy: 0.8799 - val_loss: 0.3492 - val_accuracy: 0.9033\n",
      "Epoch 8/100\n",
      "495/495 [==============================] - 51s 104ms/step - loss: 0.3674 - accuracy: 0.8916 - val_loss: 0.3347 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "495/495 [==============================] - 52s 105ms/step - loss: 0.3465 - accuracy: 0.8992 - val_loss: 0.3179 - val_accuracy: 0.9083\n",
      "Epoch 10/100\n",
      "495/495 [==============================] - 52s 106ms/step - loss: 0.3182 - accuracy: 0.9095 - val_loss: 0.3105 - val_accuracy: 0.9067\n",
      "Epoch 11/100\n",
      "495/495 [==============================] - 51s 103ms/step - loss: 0.2998 - accuracy: 0.9105 - val_loss: 0.2991 - val_accuracy: 0.9117\n",
      "Epoch 12/100\n",
      "495/495 [==============================] - 51s 104ms/step - loss: 0.2795 - accuracy: 0.9172 - val_loss: 0.2947 - val_accuracy: 0.9133\n",
      "Epoch 13/100\n",
      "495/495 [==============================] - 52s 104ms/step - loss: 0.2628 - accuracy: 0.9214 - val_loss: 0.2823 - val_accuracy: 0.9117\n",
      "Epoch 14/100\n",
      "495/495 [==============================] - 52s 105ms/step - loss: 0.2488 - accuracy: 0.9235 - val_loss: 0.2814 - val_accuracy: 0.9117\n"
     ]
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=1, restore_best_weights=True)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "history = model.fit(train_images, train_labels, batch_size=20, epochs=100, validation_data=(validation_images,validation_labels), callbacks=[monitor], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 3s 145ms/step - loss: 0.2733 - accuracy: 0.9167\n",
      "Test loss: 0.27327215671539307\n",
      "Test accuracy: 0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "# model.save(\"tmp6\")\n",
    "# model = keras.models.load_model('CBAM_pooling_r16_false')\n",
    "\n",
    "score = model.evaluate(test_images, test_labels)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    # #plot accuracy\n",
    "    # plt.subplot(221)\n",
    "    # plt.plot(history.history[\"accuracy\"], 'bo--', label=\"acc\")\n",
    "    # plt.plot(history.history[\"val_accuracy\"], \"ro--\", label = \"val_acc\")\n",
    "    # plt.title(\"train_acc vs val_acc\")\n",
    "    # plt.ylabel(\"accuracy\")\n",
    "    # plt.xlabel(\"epochs\")\n",
    "    # plt.legend()\n",
    "    \n",
    "    #plot loss function\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history[\"loss\"], 'bo--', label=\"loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], \"ro--\", label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_accuracy_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_images)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "60f60e76100a664673c60b5022fd886353d7910fb19790531071192a56dbe781"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
