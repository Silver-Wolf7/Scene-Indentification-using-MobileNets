{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import MobileNet\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_labels(file):\n",
    "    labels_file = open(file, \"r\")\n",
    "    labels = []\n",
    "    \n",
    "    for line in labels_file:\n",
    "        label = line.strip()\n",
    "        labels.append(label)\n",
    "    \n",
    "    labels_file.close()\n",
    "    \n",
    "    return labels\n",
    "\n",
    "\n",
    "#list of all labels\n",
    "class_names = list_labels(\"./CamSDD/Labels.txt\")\n",
    "class_name_labels = {class_name:i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "\n",
    "\n",
    "def load_data(folder):\n",
    "    Category = [\"training\", \"test\", \"validation\"]\n",
    "    output = []\n",
    "    \n",
    "    for category in Category:\n",
    "        print(\"Loading {}\".format(category))\n",
    "        path = os.path.join(folder, category)\n",
    "        print(path)\n",
    "        images = []\n",
    "        labels = []\n",
    "        \n",
    "        for sub_folder in os.listdir(path):\n",
    "            label = class_name_labels[sub_folder]\n",
    "            \n",
    "            #Iterating through all images\n",
    "            for file in os.listdir(os.path.join(path, sub_folder)):\n",
    "                \n",
    "                #getting the image path\n",
    "                img_path = os.path.join(os.path.join(path, sub_folder), file)\n",
    "                \n",
    "                #appending image and corresponding label\n",
    "                images.append(cv2.imread(img_path))\n",
    "                labels.append(label)\n",
    "            \n",
    "        #check that data type doesn't affect accuracy\n",
    "        images = np.array(images, dtype='float32')\n",
    "        labels = np.array(labels, dtype='int32')\n",
    "        \n",
    "        output.append((images, labels))\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "#displays 25 images with labels\n",
    "def display_examples(class_names, images, labels):\n",
    "    figsize = (20, 20)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    fig.suptitle(\"Example of images\", fontsize=16)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        # image = cv2.resize(images[i], figsize)\n",
    "        plt.imshow(images[i].astype(np.uint8))\n",
    "        plt.xlabel(class_names[labels[i]])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training\n",
      ".\\CamSDD\\training\n",
      "Loading test\n",
      ".\\CamSDD\\test\n",
      "Loading validation\n",
      ".\\CamSDD\\validation\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels), (validation_images, validation_labels)= load_data(\".\\\\CamSDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffling train data\n",
    "train_images, train_labels = shuffle(train_images, train_labels, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_examples(class_names, train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "#imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "#check how many neurons should be discarded\n",
    "base_model=MobileNet(weights='imagenet',include_top=False) \n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024, activation='sigmoid')(x)\n",
    "x=Dropout(0.7)(x)\n",
    "output = Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking model architecture\n",
    "# print(model.summary())\n",
    "for i,layer in enumerate(model.layers):\n",
    "  print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the ones we created above (check which method)\n",
    "# for layer in model.layers[:-4]:\n",
    "#     layer.trainable=False\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "495/495 [==============================] - 328s 654ms/step - loss: 2.3049\n",
      "Epoch 2/15\n",
      "495/495 [==============================] - 295s 597ms/step - loss: 1.6388\n",
      "Epoch 3/15\n",
      "495/495 [==============================] - 299s 605ms/step - loss: 1.4537\n",
      "Epoch 4/15\n",
      "495/495 [==============================] - 294s 594ms/step - loss: 1.3266\n",
      "Epoch 5/15\n",
      "495/495 [==============================] - 296s 598ms/step - loss: 1.2448\n",
      "Epoch 6/15\n",
      "495/495 [==============================] - 294s 594ms/step - loss: 1.1896\n",
      "Epoch 7/15\n",
      "495/495 [==============================] - 295s 596ms/step - loss: 1.1109\n",
      "Epoch 8/15\n",
      "495/495 [==============================] - 298s 601ms/step - loss: 1.0867\n",
      "Epoch 9/15\n",
      "495/495 [==============================] - 317s 641ms/step - loss: 1.0431\n",
      "Epoch 10/15\n",
      "495/495 [==============================] - 302s 611ms/step - loss: 1.0134\n",
      "Epoch 11/15\n",
      "495/495 [==============================] - 292s 589ms/step - loss: 0.9811\n",
      "Epoch 12/15\n",
      "495/495 [==============================] - 309s 625ms/step - loss: 0.9433\n",
      "Epoch 13/15\n",
      "495/495 [==============================] - 304s 615ms/step - loss: 0.9287\n",
      "Epoch 14/15\n",
      "495/495 [==============================] - 310s 625ms/step - loss: 0.8954\n",
      "Epoch 15/15\n",
      "495/495 [==============================] - 321s 649ms/step - loss: 0.8711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ab07e9c10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check what loss function they used\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=1e-4,\n",
    "#     decay_steps=1485,\n",
    "#     decay_rate=0.1)\n",
    "\n",
    "# model.compile(optimizer=Adam(learning_rate=lr_schedule), loss='sparse_categorical_crossentropy')\n",
    "\n",
    "class ADJUSTLR(keras.callbacks.Callback):\n",
    "    def __init__ (self, model, freq, factor, verbose):\n",
    "        self.model=model\n",
    "        self.freq=freq\n",
    "        self.factor =factor\n",
    "        self.verbose=verbose\n",
    "        self.adj_epoch=freq\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch + 1 == self.adj_epoch: # adjust the learning rate\n",
    "            lr=float(tf.keras.backend.get_value(self.model.optimizer.lr)) # get the current learning rate\n",
    "            new_lr=lr * self.factor\n",
    "            self.adj_epoch +=self.freq\n",
    "            if self.verbose == 1:\n",
    "                print('\\non epoch ',epoch + 1, ' lr was adjusted from ', lr, ' to ', new_lr)\n",
    "            tf.keras.backend.set_value(self.model.optimizer.lr, new_lr) # set the learning rate in the optimizer\n",
    "freq=3\n",
    "factor=0.1\n",
    "verbose=1\n",
    "callbacks=[ADJUSTLR(model, freq, factor, verbose)]\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.fit(train_images, train_labels, batch_size=20, epochs=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05f77207d599572d981daf736ca0d1eaa03a714dfd02cbbd00a3d96185cb54ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
